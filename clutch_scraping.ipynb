{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium-stealth\n",
    "# !pip install webdriver-manager\n",
    "# !pip install seleniumbase\n",
    "# !C:\\Users\\chira\\Desktop\\clutch\\clutch\\Scripts\\python.exe -m pip install seleniumbase\n",
    "# !pip install pandas\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37da436-d441-4c73-a2a0-f64ca127566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import undetected_chromedriver as uc\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c061bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from seleniumbase import SB\n",
    "\n",
    "# with SB(test=True, uc=True) as sb:\n",
    "#     sb.open('https://clutch.co/')\n",
    "#     # sb.type('[title=\"Search\"]', \"SeleniumBase GitHub page\\n\")\n",
    "#     # sb.click('[href*=\"github.com/seleniumbase/\"]')\n",
    "#     sb.save_screenshot_to_logs()  # ./latest_logs/\n",
    "#     print(sb.get_page_title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3ed918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumbase import Driver\n",
    "\n",
    "# initialize driver in GUI mode with UC enabled\n",
    "driver = Driver(uc=True, headless=False)\n",
    "driver.get('https://clutch.co/')\n",
    "# driver.save_screenshot('nowsecure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54bea015",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[@id='focus-chart_dropdown-button']\"))\n",
    "            )\n",
    "driver.execute_script(\"arguments[0].click();\", ele)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a0d89e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from webdriver_manager.core.os_manager import OperationSystemManager, ChromeType\n",
    "\n",
    "# option = uc.ChromeOptions()\n",
    "\n",
    "# option.add_argument('--ignore-ssl-errors')\n",
    "# option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "# option.add_argument('--headless=new') \n",
    "# option.add_argument('--no-sandbox') \n",
    "# option.add_argument(\"--window-size=1920x1080\")\n",
    "# option.add_argument('--disable-dev-shm-usage')\n",
    "# option.add_argument(\"--disable-gpu\")\n",
    "\n",
    "# # Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 Edg/133.0.0.0\n",
    "# option.add_argument('user-agent=\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15\"')\n",
    "\n",
    "# br_ver = OperationSystemManager().get_browser_version_from_os(ChromeType.GOOGLE)\n",
    "# ver_main=int(br_ver.split('.')[0])\n",
    "\n",
    "# driver = uc.Chrome(options=option, headless=True, version_main=ver_main)\n",
    "\n",
    "# driver.get('https://clutch.co/')\n",
    "# driver.save_screenshot('nowsecure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "576fd8e2-42bc-4f4a-8211-486f5731c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = uc.Chrome(headless=True)\n",
    "\n",
    "# driver.get('https://clutch.co/')\n",
    "# driver.save_screenshot('nowsecure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "60afdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium_stealth import stealth\n",
    "# import time\n",
    "\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"start-maximized\")\n",
    "\n",
    "# # options.add_argument(\"--headless\")\n",
    "\n",
    "# options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "# options.add_experimental_option('useAutomationExtension', False)\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# stealth(driver,\n",
    "#         languages=[\"en-US\", \"en\"],\n",
    "#         vendor=\"Google Inc.\",\n",
    "#         platform=\"Win32\",\n",
    "#         webgl_vendor=\"Intel Inc.\",\n",
    "#         renderer=\"Intel Iris OpenGL Engine\",\n",
    "#         fix_hairline=True,\n",
    "#         )\n",
    "\n",
    "# driver.get('https://clutch.co/')\n",
    "# driver.save_screenshot('nowsecure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5ba95fe2-876b-4c70-9c3c-b0a8d2bb9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_type = input(\"Enter the company type\")\n",
    "\n",
    "# company_type = \"web developer\"\n",
    "\n",
    "company_type_inp_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'search-services-input'))\n",
    ")\n",
    "\n",
    "company_type_inp_box.send_keys(company_type)\n",
    "time.sleep(2)\n",
    "\n",
    "# driver.save_screenshot('nowsecure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "540cfe31-c993-4c54-be98-8be54f58626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Web Developers Packages\n",
      "2 Web Developers\n",
      "3 Web Design Packages\n",
      "4 Web Design\n",
      "5 SQL Developers\n",
      "6 BI App Developers\n",
      "7 Ipad App Developers\n",
      "8 Software Developers\n",
      "9 Sitecore Developers\n",
      "10 Software Developers Packages\n",
      "11 Wordpress Developers\n",
      "12 API Development\n",
      "\n",
      "You chose Web Developers\n"
     ]
    }
   ],
   "source": [
    "dropdown_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'search-services-results'))\n",
    ")\n",
    "\n",
    "dropdown_element_html = dropdown_element.get_attribute(\"outerHTML\")\n",
    "soup = BeautifulSoup(dropdown_element_html, 'html.parser')\n",
    "all_dropdown_items = soup.find('div').find_all(\"div\", recursive=False)\n",
    "\n",
    "for i, item in enumerate(all_dropdown_items):\n",
    "    print(i+1, item.text.strip())\n",
    "\n",
    "choice = input(\"Select the company type\")\n",
    "# choice = \"1\"\n",
    "\n",
    "print()\n",
    "print(f\"You chose {all_dropdown_items[int(choice)-1].text.strip()}\")\n",
    "\n",
    "dropdown_item = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, f\"//div[@id='search-services-results']/div[{choice}]\"))\n",
    ").click()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0063c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_location = input(\"Enter the company location\")\n",
    "# company_location = \"india\"\n",
    "\n",
    "company_location_inp_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'search-locations-input'))\n",
    ")\n",
    "\n",
    "company_location_inp_box.send_keys(company_location)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "78c4083e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Any location\n",
      "2 India\n",
      "3 Indiana, United States\n",
      "\n",
      "You chose India\n"
     ]
    }
   ],
   "source": [
    "dropdown_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'search-locations-results'))\n",
    ")\n",
    "\n",
    "dropdown_element_html = dropdown_element.get_attribute(\"outerHTML\")\n",
    "soup = BeautifulSoup(dropdown_element_html, 'html.parser')\n",
    "all_dropdown_items = soup.find('div').find_all(\"div\", recursive=False)\n",
    "\n",
    "for i, item in enumerate(all_dropdown_items):\n",
    "    print(i+1, item.text.strip())\n",
    "\n",
    "choice = input(\"Select the company location\")\n",
    "# choice = \"2\"\n",
    "print()\n",
    "print(f\"You chose {all_dropdown_items[int(choice)-1].text.strip()}\")\n",
    "\n",
    "dropdown_item = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, f\"//div[@id='search-locations-results']/div[{choice}]\"))\n",
    ").click()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "fe277c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_btn = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.ID, 'search-submit'))\n",
    ").click()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5d174662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_companies_tab = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_element_located((By.XPATH, \"//a[@aria-label='Go to the All Companies Page']\"))\n",
    "# ).click()\n",
    "\n",
    "# time.sleep(2)\n",
    "\n",
    "# all_companies_visit_link = WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_all_elements_located((By.XPATH, \"//ul[@id='providers__list']//div[@class='provider__cta-container']/a[1]\"))\n",
    "#     )\n",
    "\n",
    "# company_visit_link = all_companies_visit_link[1]\n",
    "\n",
    "# company_visit_link.click()\n",
    "\n",
    "# time.sleep(2)\n",
    "\n",
    "# WebDriverWait(driver, 10).until(lambda d: len(d.window_handles) > 1)\n",
    "\n",
    "# driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "# time.sleep(1)\n",
    "\n",
    "# print(\"Current URL:\", driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "48c76700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_data = dict()\n",
    "# company_data['clutch_url'] = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a4b2a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary(company_data):\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        comp_name = soup.find(\"h1\", class_=\"profile-header__title\").text.strip()\n",
    "        company_data[\"name\"] = comp_name\n",
    "        # print(comp_name)\n",
    "    except Exception as e:\n",
    "        print(f\"No company name present. Error: \", e)\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        comp_link = soup.find(\"a\", class_=\"website-link__item\")[\"href\"]\n",
    "        company_data[\"company_url\"] = comp_link\n",
    "        # print(comp_link)\n",
    "    except Exception as e:\n",
    "        print(f\"No company link present. Error: \", e)\n",
    "        company_data[\"company_url\"] = \"\"\n",
    "\n",
    "    try:\n",
    "        tagline = soup.find(\"h2\", class_=\"profile-summary__tagline\").text.strip()\n",
    "        company_data[\"tagline\"] = tagline\n",
    "        # print(tagline)\n",
    "    except Exception as e:\n",
    "        print(f\"No tagline present. Error: \", e)\n",
    "        company_data[\"tagline\"] = \"\"\n",
    "\n",
    "    try:\n",
    "        summary = soup.find(\"div\", id=\"profile-summary-text\").text.strip()\n",
    "        summary = summary.replace(\"Read more...\", \"\")\n",
    "        company_data[\"summary\"] = summary\n",
    "        # print(summary)\n",
    "    except Exception as e:\n",
    "        print(f\"No summary present. Error: \", e)\n",
    "        company_data[\"summary\"] = \"\"\n",
    "\n",
    "    try:\n",
    "        summary_table_items = soup.find('ul', class_='profile-summary__details').find_all('li', recursive=False)\n",
    "        for item in summary_table_items:\n",
    "            if \"data-tooltip-content\" in item.attrs:\n",
    "                try:\n",
    "                    tooltip = item[\"data-tooltip-content\"]\n",
    "                    val = item.find_all('span', recursive=False)[-1].text.strip()\n",
    "                    company_data[tooltip] = val\n",
    "                    # print(tooltip, \":\", val)\n",
    "                except Exception as e:\n",
    "                    print(f\"Some error occured while extracting one of the summary table data. Error: \", e)\n",
    "    except Exception as e:\n",
    "        print(f\"No summary table present. Error: \", e)\n",
    "\n",
    "    try:\n",
    "        locations_list = []\n",
    "        all_locations = soup.find('div', id=\"profile-locations-modal\").find('ul', class_='profile-modal--list').find_all('li', recursive=False)\n",
    "        for location in all_locations:\n",
    "            location_name = location.text.strip()\n",
    "            locations_list.append(location_name)\n",
    "            # print(location_name)\n",
    "        if locations_list:\n",
    "            company_data[\"<i>Location</i>\"] = locations_list\n",
    "    except Exception as e:\n",
    "        print(f\"No location present from {comp_name}. Error: \", e)\n",
    "\n",
    "    try: \n",
    "        languages_list = []\n",
    "        all_languages = soup.find('div', id=\"profile-languages-modal\").find('ul', class_='profile-modal--list').find_all('li', recursive=False)\n",
    "        for language in all_languages:\n",
    "            language_name = language.text.strip()\n",
    "            languages_list.append(language_name)\n",
    "            # print(language_name)\n",
    "        if languages_list:\n",
    "            company_data[\"<i>Language</i>\"] = languages_list\n",
    "    except Exception as e:\n",
    "        print(f\"No language present from {comp_name}. Error: \", e)\n",
    "    \n",
    "    try:\n",
    "        timezone_list = []\n",
    "        all_timezone = soup.find('div', id=\"profile-timezone-modal\").find('div', class_='profile-modal--list').find_all('dl', recursive=False)\n",
    "        for timezone in all_timezone:\n",
    "            timezone_name = timezone.find('dt').text.strip()+\" \"+timezone.find('dd').text.strip()\n",
    "            timezone_list.append(timezone_name)\n",
    "            # print(timezone_name)\n",
    "        if timezone_list:\n",
    "            company_data[\"<i>Timezone</i>\"] = timezone_list\n",
    "    except Exception as e:\n",
    "        print(f\"No timezone present from {comp_name}. Error: \", e)\n",
    "\n",
    "    try:\n",
    "        video_link_element = soup.find(\"div\", id=\"video-modal\").find(\"div\", class_=\"video-modal__video-wrapper\").find(\"iframe\")[\"src\"]\n",
    "        video_link = \"https:\"+video_link_element\n",
    "        company_data[\"company_video_link\"] = video_link\n",
    "        # print(video_link)\n",
    "    except Exception as e:\n",
    "        print(f\"No video link present from {comp_name}. Error: \", e)\n",
    "\n",
    "    try:\n",
    "        social_links = soup.find(\"div\", class_=\"profile-summary__social\").find_all(\"a\")\n",
    "        for link in social_links:\n",
    "            social_name = link[\"title\"].strip()\n",
    "            social_url = link[\"href\"].strip()\n",
    "            company_data[social_name] = social_url\n",
    "            # print(social_name, \":\", social_url)\n",
    "    except Exception as e:\n",
    "        print(f\"No social link present from {comp_name}. Error: \", e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_charts(company_data):\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    all_services = []\n",
    "    services_items = soup.find(\"ul\", id=\"legend_list\").find_all(\"li\", recursive=False)\n",
    "    for item in services_items:\n",
    "        if item.find(\"a\"):\n",
    "            service_name = item.find(\"a\").text.strip()\n",
    "        else:\n",
    "            service_name = item.find(string=True, recursive=False).strip()\n",
    "        service_precent = item.find(\"span\").text.strip()\n",
    "        all_services.append([service_name, service_precent])\n",
    "    company_data[\"services_provided\"] = all_services\n",
    "    print(all_services)  \n",
    "\n",
    "    # WebDriverWait(driver, 10).until(\n",
    "    #     EC.element_to_be_clickable((By.XPATH, \"//button[@data-id='industries']\"))\n",
    "    # ).click()\n",
    "\n",
    "    abc = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[@data-id='industries']\"))\n",
    "    )\n",
    "    driver.execute_script(\"arguments[0].click();\", abc)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    all_industries = []\n",
    "    industries_items = soup.find(\"ul\", id=\"legend_list\").find_all(\"li\", recursive=False)\n",
    "    for item in industries_items:\n",
    "        if item.find(\"a\"):\n",
    "            industry_name = item.find(\"a\").text.strip()\n",
    "        else:\n",
    "            industry_name = item.find(string=True, recursive=False).strip()\n",
    "        industry_precent = item.find(\"span\").text.strip()\n",
    "        all_industries.append([industry_name, industry_precent])\n",
    "    company_data[\"industries\"] = all_industries\n",
    "    print(all_industries)\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[@data-id='clients']\"))\n",
    "    ).click()\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    all_clients = []\n",
    "    clients_items = soup.find(\"ul\", id=\"legend_list\").find_all(\"li\", recursive=False)\n",
    "    for item in clients_items:\n",
    "        if item.find(\"a\"):\n",
    "            client_name = item.find(\"a\").text.strip()\n",
    "        else:\n",
    "            client_name = item.find(string=True, recursive=False).strip()\n",
    "        client_precent = item.find(\"span\").text.strip()\n",
    "        all_clients.append([client_name, client_precent])\n",
    "    company_data[\"clients\"] = all_clients\n",
    "    print(all_clients)\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[@data-id='focus']\"))\n",
    "    ).click()\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    all_focus = {}\n",
    "\n",
    "    try:\n",
    "        \n",
    "        try:\n",
    "            focus_dropdown_divs = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, \"//div[@id='focus-chart_dropdown-list']/div\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't find the focus dropdown divs. Error: \", e)\n",
    "            focus_dropdown_btn = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[@id='focus-chart_dropdown-button']\"))\n",
    "                )\n",
    "            driver.execute_script(\"arguments[0].click();\", focus_dropdown_btn)\n",
    "            time.sleep(1)\n",
    "\n",
    "            focus_dropdown_divs = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, \"//div[@id='focus-chart_dropdown-list']/div\"))\n",
    "            )\n",
    "\n",
    "        for div in focus_dropdown_divs:\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[@id='focus-chart_dropdown-button']\"))\n",
    "                ).click()\n",
    "                time.sleep(1)\n",
    "\n",
    "                div.click()\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(\"Couldn't click on the focus dropdown div. Error: \", e)\n",
    "                focus_dropdown_btn = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[@id='focus-chart_dropdown-button']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].click();\", focus_dropdown_btn)\n",
    "                time.sleep(1)\n",
    "                input_element = div.find_element(By.TAG_NAME, \"input\")\n",
    "                driver.execute_script(\"arguments[0].click();\", input_element)\n",
    "                time.sleep(1)\n",
    "\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            tech_stack_name = soup.find(\"div\", id=\"focus-chart_dropdown\").find(\"button\").find(\"span\").text.strip()\n",
    "            \n",
    "            all_tech = []\n",
    "            tech_items = soup.find(\"ul\", id=\"legend_list\").find_all(\"li\", recursive=False)\n",
    "            for item in tech_items:\n",
    "                if item.find(\"a\"):\n",
    "                    tech_name = item.find(\"a\").text.strip()\n",
    "                else:\n",
    "                    tech_name = item.find(string=True, recursive=False).strip()\n",
    "                tech_precent = item.find(\"span\").text.strip()\n",
    "                all_tech.append([tech_name, tech_precent])\n",
    "            all_focus[tech_stack_name] = all_tech\n",
    "        company_data[\"focus\"] = all_focus\n",
    "        # print(all_focus)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't expand the focus dropdown. Error: \", e)\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        tech_stack_name = soup.find(\"div\", id=\"focus-chart_dropdown\").find(\"button\").find(\"span\").text.strip()\n",
    "            \n",
    "        all_tech = []\n",
    "        tech_items = soup.find(\"ul\", id=\"legend_list\").find_all(\"li\", recursive=False)\n",
    "        for item in tech_items:\n",
    "            if item.find(\"a\"):\n",
    "                tech_name = item.find(\"a\").text.strip()\n",
    "            else:\n",
    "                tech_name = item.find(string=True, recursive=False).strip()\n",
    "            tech_precent = item.find(\"span\").text.strip()\n",
    "            all_tech.append([tech_name, tech_precent])\n",
    "        all_focus[tech_stack_name] = all_tech\n",
    "        company_data[\"focus\"] = all_focus\n",
    "        # print(all_focus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mobile App Development', '40%'], ['Custom Software Development', '20%'], ['UX/UI Design', '20%'], ['Web Development', '20%']]\n",
      "[['Mobile App Development', '40%'], ['Custom Software Development', '20%'], ['UX/UI Design', '20%'], ['Web Development', '20%']]\n",
      "[['Mobile App Development', '40%'], ['Custom Software Development', '20%'], ['UX/UI Design', '20%'], ['Web Development', '20%']]\n",
      "Couldn't find the focus dropdown divs. Error:  Message: \n",
      "\n",
      "Couldn't expand the focus dropdown. Error:  Message: \n",
      "\n",
      "{'AWS Consulting Services': [['Mobile App Development', '40%'], ['Custom Software Development', '20%'], ['UX/UI Design', '20%'], ['Web Development', '20%']]}\n"
     ]
    }
   ],
   "source": [
    "# extract_charts({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3b40551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_excel(json_data):\n",
    "    columns = [\"Company Name\", \"Company URL\", \"Clutch URL\", \"Tagline\", \"Description\", \"Min Project Size\", \n",
    "           \"Avg Hourly Rate\", \"No of Employees\", \"Locations\", \"Founding Year\", \"Languages\", \"Timezones\",\n",
    "           \"Company Video Link\", \"LinkedIn URL\", \"Facebook URL\", \"Twitter URL\", \"Instagram URL\", \n",
    "           \"Services Provides\", \"Focus\", \"Industries\", \"Clients\"]\n",
    "\n",
    "    data = []\n",
    "    for json_dp in json_data:\n",
    "        dp = []\n",
    "        dp.append(json_dp[\"name\"])\n",
    "        dp.append(json_dp[\"company_url\"])\n",
    "        dp.append(json_dp[\"clutch_url\"])\n",
    "        dp.append(json_dp[\"tagline\"])\n",
    "        dp.append(json_dp[\"summary\"])\n",
    "        dp.append(json_dp[\"<i>Min. project size</i>\"] if \"<i>Min. project size</i>\" in json_dp else \"\")\n",
    "        dp.append(json_dp[\"<i>Avg. hourly rate</i>\"] if \"<i>Avg. hourly rate</i>\" in json_dp else \"\")\n",
    "        dp.append(json_dp[\"<i>Employees</i>\"] if \"<i>Employees</i>\" in json_dp else \"\")\n",
    "        location = ' | '.join(json_dp.get(\"<i>Location</i>\", [])) if isinstance(json_dp.get(\"<i>Location</i>\", []), list) else json_dp.get(\"<i>Location</i>\", \"\")\n",
    "        dp.append(location)\n",
    "        dp.append(json_dp[\"<i>Founded</i>\"] if \"<i>Founded</i>\" in json_dp else \"\")\n",
    "        languages = ' | '.join(json_dp.get(\"<i>Language</i>\", [])) if isinstance(json_dp.get(\"<i>Language</i>\", []), list) else json_dp.get(\"<i>Language</i>\", \"\")\n",
    "        dp.append(languages)\n",
    "        timezones = ' | '.join(json_dp.get(\"<i>Timezone</i>\", [])) if isinstance(json_dp.get(\"<i>Timezone</i>\", []), list) else json_dp.get(\"<i>Timezone</i>\", \"\")\n",
    "        dp.append(timezones)\n",
    "        dp.append(json_dp[\"company_video_link\"] if \"company_video_link\" in json_dp else \"\")\n",
    "        dp.append(json_dp[\"LinkedIn\"] if \"LinkedIn\" in json_dp else \"\")\n",
    "        dp.append(json_dp[\"Facebook\"] if \"Facebook\" in json_dp else \"\")\n",
    "        dp.append(json_dp[\"Twitter\"] if \"Twitter\" in json_dp else \"\")\n",
    "        dp.append(json_dp[\"Instagram\"] if \"Instagram\" in json_dp else \"\")\n",
    "        services = ', '.join(f'{service[0]} {service[1]}' for service in json_dp[\"services_provided\"])\n",
    "        dp.append(services)\n",
    "        focus = \"\"\n",
    "        for tech_stack in json_dp[\"focus\"]:\n",
    "            focus += tech_stack + \" : \"\n",
    "            focus += \", \".join([tech[0]+\" \"+tech[1] for tech in json_dp[\"focus\"][tech_stack]])\n",
    "            focus += \" | \"\n",
    "        dp.append(focus[:-3])\n",
    "        industries = ', '.join(f'{industry[0]} {industry[1]}' for industry in json_dp[\"industries\"])\n",
    "        dp.append(industries)\n",
    "        clients = ', '.join(f'{client[0]} {client[1]}' for client in json_dp[\"clients\"])\n",
    "        dp.append(clients)\n",
    "\n",
    "        data.append(dp)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    with pd.ExcelWriter(\"data.xlsx\", mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "        df.to_excel(writer, sheet_name='Sheet1', index=False, header=False, startrow=writer.sheets['Sheet1'].max_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "662feb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_urls = pd.read_excel(\"data.xlsx\")\n",
    "all_urls = set(all_urls.loc[:, \"Clutch URL\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c699fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 234\n",
      "Currently processsing page 5\n",
      "Aalpha Information Systems India Pvt. Ltd \n",
      "https://clutch.co/profile/aalpha-information-systems-india\n",
      "Already processed this company. Skipping...\n",
      "Aalpha Information Systems India Pvt. Ltd \n",
      "https://clutch.co/profile/aalpha-information-systems-india\n",
      "Already processed this company. Skipping...\n",
      "Techuz InfoWeb Pvt. Ltd. \n",
      "https://clutch.co/profile/techuz-infoweb\n",
      "Already processed this company. Skipping...\n",
      "ATEAM SOFT SOLUTIONS \n",
      "https://clutch.co/profile/ateam-soft-solutions\n",
      "Already processed this company. Skipping...\n",
      "Qualhon Informatics Pvt. Ltd. \n",
      "https://clutch.co/profile/qualhon-informatics\n",
      "Already processed this company. Skipping...\n",
      "Radiansys Inc \n",
      "https://clutch.co/profile/radiansys\n",
      "Already processed this company. Skipping...\n",
      "LN Webworks Private Limited \n",
      "https://clutch.co/profile/ln-webworks-private\n",
      "Already processed this company. Skipping...\n",
      "Brainium Information Technologies \n",
      "https://clutch.co/profile/brainium-information-technologies\n",
      "Already processed this company. Skipping...\n",
      "Capital Numbers \n",
      "https://clutch.co/profile/capital-numbers\n",
      "Already processed this company. Skipping...\n",
      "NetSet Software Solutions \n",
      "https://clutch.co/profile/netset-software-solutions\n",
      "Already processed this company. Skipping...\n",
      "UPDOTÂ® \n",
      "https://clutch.co/profile/updot\n",
      "Already processed this company. Skipping...\n",
      "AXAT Technologies PVT LTD \n",
      "https://clutch.co/profile/axat-technologies\n",
      "Already processed this company. Skipping...\n",
      "ShubhiTech Private Limited \n",
      "https://clutch.co/profile/shubhitech-private\n",
      "Already processed this company. Skipping...\n",
      "i-HiddenTalent \n",
      "https://clutch.co/profile/i-hiddentalent\n",
      "Already processed this company. Skipping...\n",
      "Quixta \n",
      "https://clutch.co/profile/quixta\n",
      "Already processed this company. Skipping...\n",
      "Ahex Technologies \n",
      "https://clutch.co/profile/ahex-technologies\n",
      "Already processed this company. Skipping...\n",
      "Bacancy \n",
      "https://clutch.co/profile/bacancy\n",
      "Already processed this company. Skipping...\n",
      "WPWeb Infotech \n",
      "https://clutch.co/profile/wpweb-infotech\n",
      "Already processed this company. Skipping...\n",
      "MOBIKASA \n",
      "https://clutch.co/profile/mobikasa\n",
      "Already processed this company. Skipping...\n",
      "i-HiddenTalent \n",
      "https://clutch.co/profile/i-hiddentalent\n",
      "Already processed this company. Skipping...\n",
      "ROCKETECH \n",
      "https://clutch.co/profile/rocketech\n",
      "Already processed this company. Skipping...\n",
      "Rasonix \n",
      "https://clutch.co/profile/rasonix\n",
      "Already processed this company. Skipping...\n",
      "Bacancy \n",
      "https://clutch.co/profile/bacancy\n",
      "Already processed this company. Skipping...\n",
      "Aubergine Solutions | UX + AI + Product Development Consulting \n",
      "https://clutch.co/profile/aubergine-solutions-ux-ai-product-development-consulting\n",
      "Already processed this company. Skipping...\n",
      "Multidots \n",
      "https://clutch.co/profile/multidots\n",
      "Already processed this company. Skipping...\n",
      "TatvaSoft \n",
      "https://clutch.co/profile/tatvasoft\n",
      "Already processed this company. Skipping...\n",
      "Salt Technologies \n",
      "https://clutch.co/profile/salt-technologies\n",
      "Already processed this company. Skipping...\n",
      "Unico Connect \n",
      "https://clutch.co/profile/unico-connect\n",
      "Already processed this company. Skipping...\n",
      "Mobulous \n",
      "https://clutch.co/profile/mobulous\n",
      "Already processed this company. Skipping...\n",
      "Unified Infotech \n",
      "https://clutch.co/profile/unified-infotech\n",
      "Already processed this company. Skipping...\n",
      "Axelerant \n",
      "https://clutch.co/profile/axelerant\n",
      "Already processed this company. Skipping...\n",
      "Promatics Technologies \n",
      "https://clutch.co/profile/promatics-technologies\n",
      "Already processed this company. Skipping...\n",
      "Netclues Inc. \n",
      "https://clutch.co/profile/netclues\n",
      "Already processed this company. Skipping...\n",
      "WebSpero Solutions \n",
      "https://clutch.co/profile/webspero-solutions\n",
      "Already processed this company. Skipping...\n",
      "Think To Share \n",
      "https://clutch.co/profile/think-share\n",
      "Already processed this company. Skipping...\n",
      "Mallow Technologies Private Limited \n",
      "https://clutch.co/profile/mallow-technologies-private\n",
      "Already processed this company. Skipping...\n",
      "Konstant Infosolutions \n",
      "https://clutch.co/profile/konstant-infosolutions\n",
      "Already processed this company. Skipping...\n",
      "The NineHertz \n",
      "https://clutch.co/profile/ninehertz\n",
      "Already processed this company. Skipping...\n",
      "Sourceved Technologies Pvt Ltd \n",
      "https://clutch.co/profile/sourceved-technologies\n",
      "Already processed this company. Skipping...\n",
      "Digital Aptech \n",
      "https://clutch.co/profile/digital-aptech\n",
      "Already processed this company. Skipping...\n",
      "Ahex Technologies \n",
      "https://clutch.co/profile/ahex-technologies\n",
      "Already processed this company. Skipping...\n",
      "Crest Coder Private Limited \n",
      "https://clutch.co/profile/crest-coder-private\n",
      "Already processed this company. Skipping...\n",
      "W3care Technologies Pvt. Ltd. \n",
      "https://clutch.co/profile/w3care-technologies\n",
      "iTechnolabs Inc \n",
      "https://clutch.co/profile/itechnolabs\n",
      "No video link present from iTechnolabs Inc. Error:  'NoneType' object has no attribute 'find'\n",
      "techahead \n",
      "https://clutch.co/profile/techahead\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:70\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[286]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mextract_charts\u001b[39m\u001b[34m(company_data)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m div \u001b[38;5;129;01min\u001b[39;00m focus_dropdown_divs:\n\u001b[32m     70\u001b[39m     WebDriverWait(driver, \u001b[32m10\u001b[39m).until(\n\u001b[32m     71\u001b[39m         EC.element_to_be_clickable((By.XPATH, \u001b[33m\"\u001b[39m\u001b[33m//button[@id=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfocus-chart_dropdown-button\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     72\u001b[39m     ).click()\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     div.click()\n\u001b[32m     76\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "pagination_nav = soup.find(\"nav\", id=\"pagination-nav\").find(\"div\").find_all(\"a\", recursive=False)\n",
    "no_of_pages = int(pagination_nav[-2].text.strip())\n",
    "print(f\"Total pages: {no_of_pages}\")\n",
    "\n",
    "all_companies_list = []\n",
    "\n",
    "for i in range(no_of_pages):\n",
    "    # if i==20:\n",
    "    #     break\n",
    "\n",
    "    # if i<4:\n",
    "    #     continue\n",
    "\n",
    "    print(f\"Currently processsing page {i+1}\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        all_companies_tab = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//a[@aria-label='Go to the All Companies Page']\"))\n",
    "        ).click()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to click all companies tab. Ex: \", ex)\n",
    "\n",
    "    all_companies_visit_link = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//ul[@id='providers__list']//div[@class='provider__cta-container']/a[1]\"))\n",
    "    )\n",
    "\n",
    "    for j, company_visit_link in enumerate(all_companies_visit_link):\n",
    "        # if j==2:\n",
    "        #     break\n",
    "\n",
    "        try:\n",
    "            # driver.execute_script(\"arguments[0].scrollIntoView(true);\", company_visit_link)\n",
    "            # time.sleep(10)\n",
    "            # driver.execute_script(\"arguments[0].click();\", company_visit_link)\n",
    "            comp_name = company_visit_link.get_attribute(\"title\")[5:-7]\n",
    "            print(comp_name)\n",
    "\n",
    "            comp_url = company_visit_link.get_attribute(\"href\")\n",
    "            print(comp_url)\n",
    "\n",
    "            if comp_url in all_urls:\n",
    "                print(\"Already processed this company. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                company_visit_link.click()\n",
    "            except Exception as e:\n",
    "                print(\"Standard click failed, trying JS click\")\n",
    "                driver.execute_script(\"arguments[0].click();\", company_visit_link)\n",
    "\n",
    "            try:\n",
    "                time.sleep(2)\n",
    "\n",
    "                WebDriverWait(driver, 10).until(lambda d: len(d.window_handles) > 1)\n",
    "\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                company_data = dict()\n",
    "                # print(\"Current URL:\", driver.current_url)\n",
    "                company_data['clutch_url'] = driver.current_url\n",
    "                extract_summary(company_data)\n",
    "                extract_charts(company_data)\n",
    "\n",
    "                all_companies_list.append(company_data)\n",
    "\n",
    "                add_to_excel([company_data])\n",
    "                all_urls.add(comp_url)\n",
    "            except Exception as e:\n",
    "                print(\"Unable to extract data from the company page. Exception: \", e)\n",
    "            finally:\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                time.sleep(1)\n",
    "\n",
    "            # print(company_data)\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(\"Some error occurred. Exception: \", ex)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    if i!=no_of_pages-1:\n",
    "        next_link = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//a[@aria-label='Go to Page {i+2}']\"))\n",
    "        )\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_link)\n",
    "        time.sleep(2)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f\"//a[@aria-label='Go to Page {i+2}']\")))\n",
    "            next_link.click()\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(\"Standard click failed, trying JS click\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_link)\n",
    "\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a794256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5957d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.switch_to.window(driver.window_handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "dc50a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "with open(f\"data_{curr_datetime}.json\", \"w\") as fp:\n",
    "    json.dump(all_companies_list, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c545b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clutch",
   "language": "python",
   "name": "clutch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
